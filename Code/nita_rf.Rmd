---
title: "nita"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  comment = NA,
  echo = TRUE,
  error = TRUE,
  cache = FALSE,
  message = FALSE,
  dpi = 144,
  warning = FALSE
)
```

set up
```{r}
library(readxl)
library(tidyverse)
library(dplyr)
library(lubridate)
data = read.csv("Data/cleaned_data.csv")
```

data preprocessing
```{r}
data$Time = as.character(data$Time.Aired)
data$Time = hms::as.hms(data$Time)
dat <- data %>%
  mutate(hour = hour(Time))
dat$hour = as.factor(dat$hour)
dat$Access = as.factor(dat$Access)
dat$Estimate = as.factor(dat$Estimate)
dat$daypart = as.factor(dat$daypart)
dat$DOW = as.factor(dat$DOW)
dat$Market = as.factor(dat$Market)
dat$Spot.Type = as.factor(dat$Spot.Type)
dat <- dat %>%
  select(-X)
colnames(dat)[8] = 'IMP'

## remove outliers
outliers_station = c('216', '184', '352', '311', '200', '10', '15', '192', '224', '280', '252', '72')
df <- dat %>%
  mutate(outlier = ifelse(Station.ID %in% outliers_station, 1, 0))
unseen = df %>%
  filter(GRP == 0)
training = df %>%
  filter(GRP > 0) %>%
  drop_na(IMP)
```

model training
```{r}
install.packages("randomForest")
library(randomForest)

set.seed(1234)
train <- sample(nrow(training), 0.7*nrow(training), replace = FALSE)
TrainSet <- training[train,]
ValidSet <- training[-train,]
summary(TrainSet)
summary(ValidSet)
Train <- TrainSet %>%
  select(-Date.Aired, -Impression, -Impression..000., -DMA, -Media, -Time.Aired, -Time, -daypart, -GRP)
Train$outlier = as.factor(Train$outlier)

Val <- ValidSet %>%
  select(-Date.Aired, -Impression, -Impression..000., -DMA, -Media, -Time.Aired, -Time, -daypart, -GRP)
Val$outlier = as.factor(Val$outlier)

#write.csv(Train, 'nitarftrain.csv')
```

##Cross Validation
```{r}
library(radiant)
result <- rforest(
  Train, 
  rvar = "IMP", 
  evar = c(
    "Access", "Estimate", "Market", "Spot.Cost", 
    "Station.ID", "DOW", "hour", "outlier"
  ), 
  type = "regression",
  seed = 1234
)
cv.rforest(
  result, mtry = 1:3, min.node.size = seq(1, 10, 5),
  num.trees = c(100, 200), fun = RMSE
)
```

## Final Model
```{r fig.width = 7, fig.height = 4.85, dpi = 96}
library(radiant)
result <- rforest(
  Train, 
  rvar = "IMP", 
  evar = c(
    "Access", "Estimate", "Market", "Spot.Cost", 
    "Station.ID", "DOW", "hour", "outlier"
  ), 
  type = "regression",
  seed = 1234, mtry = 3, min.node.size = 1, num.trees = 100
)
summary(result)
plot(result, plots = "vimp", custom = FALSE)

pred <- predict(result, pred_data = Train)
print(pred, n = 10)
Train <- store(Train, pred, name = "pred_rf") %>%
  mutate(se = ((IMP - pred_rf)^2))

pred2 <- predict(result, pred_data = Val)
print(pred2, n = 10)
Val <- store(Val, pred2, name = "pred_rf") %>%
  mutate(se = ((IMP - pred_rf)^2))

mse_train = mean(Train$se)
mse_train

mse_val = mean(Val$se)
mse_val
```

```{r}
print(paste0("The MSE for training set is, ", mse_train))
print(paste0("The MSE for validation set is, ", mse_val))
Traintable <- Train %>%
  select(-Length, -Spot.Type)
```
