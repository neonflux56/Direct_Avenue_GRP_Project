{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_data.csv').drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data used to build the model: 55383 rows\n",
      "data used to predict: 448456 rows\n"
     ]
    }
   ],
   "source": [
    "data0 = data[data['Impressions'] != 0].dropna()\n",
    "data1 = data[data['Impressions'] == 0]\n",
    "print('data used to build the model:', len(data0), 'rows')\n",
    "print('data used to predict:', len(data1), 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Access', 'DMA', 'Date Aired', 'Estimate', 'GRP', 'Impressions',\n",
       "       'Length', 'Market', 'Media', 'Spot Cost', 'Spot Type', 'Station ID',\n",
       "       'Time Aired', 'DOW', 'daypart'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[216, 184, 352, 311, 200]"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify outlier stations\n",
    "outlier_stations = pd.read_pickle('Code/outlier_stations.pickle')\n",
    "Outlier = list(outlier_stations[outlier_stations>=5].index)\n",
    "Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['Access','Estimate', 'Market', 'Length', 'Spot Cost', 'Station ID','DOW', 'Date Aired']\n",
    "x = data0.loc[:,feature]\n",
    "x.index = range(len(x))\n",
    "y = data0.loc[:,'Impressions']\n",
    "\n",
    "Access = pd.get_dummies(x['Access'])\n",
    "Estimate = pd.get_dummies(x['Estimate'])\n",
    "Market = pd.get_dummies(x['Market'])\n",
    "Station = pd.DataFrame({'Outlier_station': [(i in Outlier)+0 for i in x['Station ID']]})\n",
    "Month = pd.DataFrame({'Month': [datetime.datetime.strptime(i, \"%Y-%m-%d\").month for i in x['Date Aired']]})\n",
    "DOW = pd.get_dummies(x['DOW'])\n",
    "#daypart = pd.get_dummies(x['daypart'])\n",
    "Hour = pd.get_dummies([i[0:2] for i in data0['Time Aired']])\n",
    "x = pd.concat([x, Access, Estimate, Market, Station, DOW, Month, Hour], axis = 1).drop(['Access', 'Estimate', 'Market','Station ID', 'DOW', 'Date Aired', 'Length'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Spot Cost', '30BP', '30DP', '30GD', '30PM', '30PT', '30SR', '30TN',\n",
       "       '30VE', 'SV15', 'Q119', 'Q219', 'Q319', 'Q419',\n",
       "       'Cable                         ', 'DirecTV                       ',\n",
       "       'Dish Network                  ', 'National Network              ',\n",
       "       'Outlier_station', 'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday',\n",
       "       'Tuesday', 'Wednesday', 'Month', '00', '01', '02', '03', '04', '05',\n",
       "       '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17',\n",
       "       '18', '19', '20', '21', '22', '23'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 833.95553722\n",
      "Iteration 2, loss = 782.83349743\n",
      "Iteration 3, loss = 732.64085086\n",
      "Iteration 4, loss = 683.51103664\n",
      "Iteration 5, loss = 648.01608067\n",
      "Iteration 6, loss = 631.74586572\n",
      "Iteration 7, loss = 628.67985307\n",
      "Iteration 8, loss = 631.26124732\n",
      "Iteration 9, loss = 618.95113637\n",
      "Iteration 10, loss = 617.06907454\n",
      "Iteration 11, loss = 615.69371873\n",
      "Iteration 12, loss = 611.76726131\n",
      "Iteration 13, loss = 611.88080163\n",
      "Iteration 14, loss = 603.96450894\n",
      "Iteration 15, loss = 596.68260589\n",
      "Iteration 16, loss = 602.85113190\n",
      "Iteration 17, loss = 611.08651832\n",
      "Iteration 18, loss = 600.23306328\n",
      "Iteration 19, loss = 619.63909244\n",
      "Iteration 20, loss = 606.87085844\n",
      "Iteration 21, loss = 602.75245794\n",
      "Iteration 22, loss = 606.71791568\n",
      "Iteration 23, loss = 597.50778019\n",
      "Iteration 24, loss = 592.30270525\n",
      "Iteration 25, loss = 592.93345494\n",
      "Iteration 26, loss = 584.47362844\n",
      "Iteration 27, loss = 580.58959694\n",
      "Iteration 28, loss = 610.97181941\n",
      "Iteration 29, loss = 587.45732945\n",
      "Iteration 30, loss = 594.34786116\n",
      "Iteration 31, loss = 594.54762996\n",
      "Iteration 32, loss = 579.77633037\n",
      "Iteration 33, loss = 588.55450487\n",
      "Iteration 34, loss = 573.19012881\n",
      "Iteration 35, loss = 572.60081840\n",
      "Iteration 36, loss = 569.74325274\n",
      "Iteration 37, loss = 566.16973011\n",
      "Iteration 38, loss = 573.29915557\n",
      "Iteration 39, loss = 575.27243899\n",
      "Iteration 40, loss = 561.28505431\n",
      "Iteration 41, loss = 563.71717859\n",
      "Iteration 42, loss = 576.80685439\n",
      "Iteration 43, loss = 557.58863257\n",
      "Iteration 44, loss = 566.62990344\n",
      "Iteration 45, loss = 550.18089289\n",
      "Iteration 46, loss = 552.66737806\n",
      "Iteration 47, loss = 562.68600058\n",
      "Iteration 48, loss = 567.67786146\n",
      "Iteration 49, loss = 552.74808350\n",
      "Iteration 50, loss = 548.37034811\n",
      "Iteration 51, loss = 596.65618957\n",
      "Iteration 52, loss = 550.90558045\n",
      "Iteration 53, loss = 543.68276585\n",
      "Iteration 54, loss = 563.98588564\n",
      "Iteration 55, loss = 614.25942021\n",
      "Iteration 56, loss = 606.04050231\n",
      "Iteration 57, loss = 600.64599776\n",
      "Iteration 58, loss = 596.34013022\n",
      "Iteration 59, loss = 568.28786101\n",
      "Iteration 60, loss = 534.55130585\n",
      "Iteration 61, loss = 555.60260848\n",
      "Iteration 62, loss = 542.68415122\n",
      "Iteration 63, loss = 533.99066901\n",
      "Iteration 64, loss = 528.90274718\n",
      "Iteration 65, loss = 526.09292574\n",
      "Iteration 66, loss = 530.04313427\n",
      "Iteration 67, loss = 520.86789912\n",
      "Iteration 68, loss = 523.49943849\n",
      "Iteration 69, loss = 514.90213660\n",
      "Iteration 70, loss = 520.72349015\n",
      "Iteration 71, loss = 520.60654744\n",
      "Iteration 72, loss = 525.76898233\n",
      "Iteration 73, loss = 564.43275279\n",
      "Iteration 74, loss = 583.48448386\n",
      "Iteration 75, loss = 521.32542813\n",
      "Iteration 76, loss = 554.50788129\n",
      "Iteration 77, loss = 508.58756853\n",
      "Iteration 78, loss = 515.93366796\n",
      "Iteration 79, loss = 542.17263389\n",
      "Iteration 80, loss = 503.76061629\n",
      "Iteration 81, loss = 497.64239311\n",
      "Iteration 82, loss = 503.47227268\n",
      "Iteration 83, loss = 500.06811927\n",
      "Iteration 84, loss = 499.83213147\n",
      "Iteration 85, loss = 527.05239389\n",
      "Iteration 86, loss = 559.81124369\n",
      "Iteration 87, loss = 586.97849916\n",
      "Iteration 88, loss = 569.32415142\n",
      "Iteration 89, loss = 498.00405343\n",
      "Iteration 90, loss = 491.32266744\n",
      "Iteration 91, loss = 486.10624437\n",
      "Iteration 92, loss = 543.57465796\n",
      "Iteration 93, loss = 584.48617364\n",
      "Iteration 94, loss = 584.01685503\n",
      "Iteration 95, loss = 585.44732562\n",
      "Iteration 96, loss = 578.67261069\n",
      "Iteration 97, loss = 534.97433606\n",
      "Iteration 98, loss = 481.20810949\n",
      "Iteration 99, loss = 486.39216158\n",
      "Iteration 100, loss = 479.74374477\n",
      "Iteration 101, loss = 478.58033719\n",
      "Iteration 102, loss = 488.74645241\n",
      "Iteration 103, loss = 589.47216755\n",
      "Iteration 104, loss = 583.10064457\n",
      "Iteration 105, loss = 581.00394439\n",
      "Iteration 106, loss = 572.20609855\n",
      "Iteration 107, loss = 572.56608413\n",
      "Iteration 108, loss = 554.79699759\n",
      "Iteration 109, loss = 485.31305249\n",
      "Iteration 110, loss = 474.11134513\n",
      "Iteration 111, loss = 477.30607735\n",
      "Iteration 112, loss = 543.71661897\n",
      "Iteration 113, loss = 578.36908625\n",
      "Iteration 114, loss = 525.92482212\n",
      "Iteration 115, loss = 475.50417382\n",
      "Iteration 116, loss = 490.64768876\n",
      "Iteration 117, loss = 469.94251414\n",
      "Iteration 118, loss = 465.88804289\n",
      "Iteration 119, loss = 478.17819016\n",
      "Iteration 120, loss = 466.28815678\n",
      "Iteration 121, loss = 459.59372451\n",
      "Iteration 122, loss = 471.34903286\n",
      "Iteration 123, loss = 546.61364328\n",
      "Iteration 124, loss = 583.74629936\n",
      "Iteration 125, loss = 576.44193061\n",
      "Iteration 126, loss = 569.80164909\n",
      "Iteration 127, loss = 568.19638818\n",
      "Iteration 128, loss = 572.14097422\n",
      "Iteration 129, loss = 527.10967253\n",
      "Iteration 130, loss = 468.49836395\n",
      "Iteration 131, loss = 467.74425100\n",
      "Iteration 132, loss = 470.00853516\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "             learning_rate_init=0.01, max_fun=15000, max_iter=1000,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=1234, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = MLPRegressor(\n",
    "    hidden_layer_sizes = (3,),\n",
    "    activation = 'relu',\n",
    "    solver=\"adam\",\n",
    "    alpha=0.0001,\n",
    "    learning_rate_init=0.01,\n",
    "    max_iter=1000,\n",
    "    verbose = True,\n",
    "    random_state=1234\n",
    ")\n",
    "mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set mse: 914.3721116110105\n",
      "test set mse: 820.1219348716304\n",
      "train set rmse: 30.238586468467908\n",
      "test set rmse: 28.63777112262109\n"
     ]
    }
   ],
   "source": [
    "pred_train = mod.predict(X_train)\n",
    "pred_test = mod.predict(X_test)\n",
    "print('train set mse:', metrics.mean_squared_error(y_train,pred_train))\n",
    "print('test set mse:', metrics.mean_squared_error(y_test,pred_test))\n",
    "print('train set rmse:', (metrics.mean_squared_error(y_train,pred_train))**0.5)\n",
    "print('test set rmse:', (metrics.mean_squared_error(y_test,pred_test))**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls = [(2,), (3,), (2, 2), (3, 3), (2,2,2), (3, 3, 3)]\n",
    "\n",
    "param_grid = {\"hidden_layer_sizes\": hls, \"alpha\": [0.0001, 0.001, 0.01]}\n",
    "\n",
    "mod_cv = GridSearchCV(\n",
    "    mod, \n",
    "    param_grid, \n",
    "    scoring= 'neg_root_mean_squared_error', \n",
    "    cv=5, n_jobs=4, refit=True, verbose=5\n",
    ")\n",
    "#mod_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=4)]: Done  90 out of  90 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 833.95553722\n",
      "Iteration 2, loss = 782.83349743\n",
      "Iteration 3, loss = 732.64085086\n",
      "Iteration 4, loss = 683.51103664\n",
      "Iteration 5, loss = 648.01608067\n",
      "Iteration 6, loss = 631.74586572\n",
      "Iteration 7, loss = 628.67985307\n",
      "Iteration 8, loss = 631.26124732\n",
      "Iteration 9, loss = 618.95113637\n",
      "Iteration 10, loss = 617.06907454\n",
      "Iteration 11, loss = 615.69371873\n",
      "Iteration 12, loss = 611.76726131\n",
      "Iteration 13, loss = 611.88080163\n",
      "Iteration 14, loss = 603.96450894\n",
      "Iteration 15, loss = 596.68260589\n",
      "Iteration 16, loss = 602.85113190\n",
      "Iteration 17, loss = 611.08651832\n",
      "Iteration 18, loss = 600.23306328\n",
      "Iteration 19, loss = 619.63909244\n",
      "Iteration 20, loss = 606.87085844\n",
      "Iteration 21, loss = 602.75245794\n",
      "Iteration 22, loss = 606.71791568\n",
      "Iteration 23, loss = 597.50778019\n",
      "Iteration 24, loss = 592.30270525\n",
      "Iteration 25, loss = 592.93345494\n",
      "Iteration 26, loss = 584.47362844\n",
      "Iteration 27, loss = 580.58959694\n",
      "Iteration 28, loss = 610.97181941\n",
      "Iteration 29, loss = 587.45732945\n",
      "Iteration 30, loss = 594.34786116\n",
      "Iteration 31, loss = 594.54762996\n",
      "Iteration 32, loss = 579.77633037\n",
      "Iteration 33, loss = 588.55450487\n",
      "Iteration 34, loss = 573.19012881\n",
      "Iteration 35, loss = 572.60081840\n",
      "Iteration 36, loss = 569.74325274\n",
      "Iteration 37, loss = 566.16973011\n",
      "Iteration 38, loss = 573.29915557\n",
      "Iteration 39, loss = 575.27243899\n",
      "Iteration 40, loss = 561.28505431\n",
      "Iteration 41, loss = 563.71717859\n",
      "Iteration 42, loss = 576.80685439\n",
      "Iteration 43, loss = 557.58863257\n",
      "Iteration 44, loss = 566.62990344\n",
      "Iteration 45, loss = 550.18089289\n",
      "Iteration 46, loss = 552.66737806\n",
      "Iteration 47, loss = 562.68600058\n",
      "Iteration 48, loss = 567.67786146\n",
      "Iteration 49, loss = 552.74808350\n",
      "Iteration 50, loss = 548.37034811\n",
      "Iteration 51, loss = 596.65618957\n",
      "Iteration 52, loss = 550.90558045\n",
      "Iteration 53, loss = 543.68276585\n",
      "Iteration 54, loss = 563.98588564\n",
      "Iteration 55, loss = 614.25942021\n",
      "Iteration 56, loss = 606.04050231\n",
      "Iteration 57, loss = 600.64599776\n",
      "Iteration 58, loss = 596.34013022\n",
      "Iteration 59, loss = 568.28786101\n",
      "Iteration 60, loss = 534.55130585\n",
      "Iteration 61, loss = 555.60260848\n",
      "Iteration 62, loss = 542.68415122\n",
      "Iteration 63, loss = 533.99066901\n",
      "Iteration 64, loss = 528.90274718\n",
      "Iteration 65, loss = 526.09292574\n",
      "Iteration 66, loss = 530.04313427\n",
      "Iteration 67, loss = 520.86789912\n",
      "Iteration 68, loss = 523.49943849\n",
      "Iteration 69, loss = 514.90213660\n",
      "Iteration 70, loss = 520.72349015\n",
      "Iteration 71, loss = 520.60654744\n",
      "Iteration 72, loss = 525.76898233\n",
      "Iteration 73, loss = 564.43275279\n",
      "Iteration 74, loss = 583.48448386\n",
      "Iteration 75, loss = 521.32542813\n",
      "Iteration 76, loss = 554.50788129\n",
      "Iteration 77, loss = 508.58756853\n",
      "Iteration 78, loss = 515.93366796\n",
      "Iteration 79, loss = 542.17263389\n",
      "Iteration 80, loss = 503.76061629\n",
      "Iteration 81, loss = 497.64239311\n",
      "Iteration 82, loss = 503.47227268\n",
      "Iteration 83, loss = 500.06811927\n",
      "Iteration 84, loss = 499.83213147\n",
      "Iteration 85, loss = 527.05239389\n",
      "Iteration 86, loss = 559.81124369\n",
      "Iteration 87, loss = 586.97849916\n",
      "Iteration 88, loss = 569.32415142\n",
      "Iteration 89, loss = 498.00405343\n",
      "Iteration 90, loss = 491.32266744\n",
      "Iteration 91, loss = 486.10624437\n",
      "Iteration 92, loss = 543.57465796\n",
      "Iteration 93, loss = 584.48617364\n",
      "Iteration 94, loss = 584.01685503\n",
      "Iteration 95, loss = 585.44732562\n",
      "Iteration 96, loss = 578.67261069\n",
      "Iteration 97, loss = 534.97433606\n",
      "Iteration 98, loss = 481.20810949\n",
      "Iteration 99, loss = 486.39216158\n",
      "Iteration 100, loss = 479.74374477\n",
      "Iteration 101, loss = 478.58033719\n",
      "Iteration 102, loss = 488.74645241\n",
      "Iteration 103, loss = 589.47216755\n",
      "Iteration 104, loss = 583.10064457\n",
      "Iteration 105, loss = 581.00394439\n",
      "Iteration 106, loss = 572.20609855\n",
      "Iteration 107, loss = 572.56608413\n",
      "Iteration 108, loss = 554.79699759\n",
      "Iteration 109, loss = 485.31305249\n",
      "Iteration 110, loss = 474.11134513\n",
      "Iteration 111, loss = 477.30607735\n",
      "Iteration 112, loss = 543.71661897\n",
      "Iteration 113, loss = 578.36908625\n",
      "Iteration 114, loss = 525.92482212\n",
      "Iteration 115, loss = 475.50417382\n",
      "Iteration 116, loss = 490.64768876\n",
      "Iteration 117, loss = 469.94251414\n",
      "Iteration 118, loss = 465.88804289\n",
      "Iteration 119, loss = 478.17819016\n",
      "Iteration 120, loss = 466.28815678\n",
      "Iteration 121, loss = 459.59372451\n",
      "Iteration 122, loss = 471.34903286\n",
      "Iteration 123, loss = 546.61364328\n",
      "Iteration 124, loss = 583.74629936\n",
      "Iteration 125, loss = 576.44193061\n",
      "Iteration 126, loss = 569.80164909\n",
      "Iteration 127, loss = 568.19638818\n",
      "Iteration 128, loss = 572.14097422\n",
      "Iteration 129, loss = 527.10967253\n",
      "Iteration 130, loss = 468.49836395\n",
      "Iteration 131, loss = 467.74425100\n",
      "Iteration 132, loss = 470.00853516\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=MLPRegressor(activation='relu', alpha=0.0001,\n",
       "                                    batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                    early_stopping=False, epsilon=1e-08,\n",
       "                                    hidden_layer_sizes=(3,),\n",
       "                                    learning_rate='constant',\n",
       "                                    learning_rate_init=0.01, max_fun=15000,\n",
       "                                    max_iter=1000, momentum=0.9,\n",
       "                                    n_iter_no_change=10,\n",
       "                                    nesterovs_momentum=True, power_t=0.5,\n",
       "                                    random_state=1234, shuffle=True,\n",
       "                                    solver='adam', tol=0.0001,\n",
       "                                    validation_fraction=0.1, verbose=True,\n",
       "                                    warm_start=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01],\n",
       "                         'hidden_layer_sizes': [(2,), (3,), (2, 2), (3, 3),\n",
       "                                                (2, 2, 2), (3, 3, 3)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_root_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set mse: 914.3721116110105\n",
      "test set mse: 820.1219348716304\n"
     ]
    }
   ],
   "source": [
    "pred_train = mod_cv.best_estimator_.predict(X_train)\n",
    "pred_test = mod_cv.best_estimator_.predict(X_test)\n",
    "print('train set mse:', metrics.mean_squared_error(y_train,pred_train))\n",
    "print('test set mse:', metrics.mean_squared_error(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set rmse: 30.238586468467908\n",
      "test set rmse: 28.63777112262109\n"
     ]
    }
   ],
   "source": [
    "print('train set rmse:', (metrics.mean_squared_error(y_train,pred_train))**0.5)\n",
    "print('test set rmse:', (metrics.mean_squared_error(y_test,pred_test))**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
