{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cleaned_data.csv').drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data used to build the model: 56574 rows\n",
      "data used to predict: 626783 rows\n"
     ]
    }
   ],
   "source": [
    "data0 = data[data['GRP'] != 0]\n",
    "data1 = data[data['GRP'] == 0]\n",
    "print('data used to build the model:', len(data0), 'rows')\n",
    "print('data used to predict:', len(data1), 'rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "#from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Access', 'DMA', 'Date Aired', 'Estimate', 'GRP', 'Impressions',\n",
       "       'Length', 'Market', 'Media', 'Spot Cost', 'Spot Type', 'Station ID',\n",
       "       'Time Aired', 'DOW', 'daypart'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[216, 184, 352, 311, 200]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify outlier stations\n",
    "# Outlier = \n",
    "outlier_stations = pd.read_pickle('Code/outlier_stations.pickle')\n",
    "Outlier = list(outlier_stations[outlier_stations>=5].index)\n",
    "Outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['Estimate', 'Access', 'Market', 'Length', 'Spot Cost', 'Station ID']\n",
    "x = data0.loc[:,feature]\n",
    "x.index = range(len(x))\n",
    "y = data0.loc[:,'GRP']\n",
    "\n",
    "Estimate = pd.get_dummies(x['Estimate'])\n",
    "Access = pd.get_dummies(x['Access'])\n",
    "Market = pd.get_dummies(x['Market'])\n",
    "#Station = pd.get_dummies(x['Station ID'])\n",
    "Station = pd.DataFrame({'Outlier_station': [(i in Outlier) for i in x['Station ID']]})\n",
    "x = pd.concat([x, Estimate, Access, Market, Station], axis = 1).drop(['Estimate', 'Access', 'Market','Station ID'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ['Estimate', 'Access', 'Market', 'Length', 'Spot Cost', 'Station ID','DOW', 'daypart']\n",
    "x = data0.loc[:,feature]\n",
    "y = data0.loc[:,'GRP']\n",
    "\n",
    "Estimate = pd.get_dummies(x['Estimate'])\n",
    "Access = pd.get_dummies(x['Access'])\n",
    "Market = pd.get_dummies(x['Market'])\n",
    "#Station = pd.get_dummies(x['Station ID'])\n",
    "Station = pd.DataFrame([(i in Outlier) for i in x['Station ID']])\n",
    "DOW = pd.get_dummies(x['DOW'])\n",
    "daypart = pd.get_dummies(x['daypart'])\n",
    "x = pd.concat([x, Estimate, Access, Market, Station, DOW, daypart], axis = 1).drop(['Estimate', 'Access', 'Market','Station ID', 'DOW', 'daypart'], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 234.73806342\n",
      "Iteration 2, loss = 0.02359299\n",
      "Iteration 3, loss = 0.01306919\n",
      "Iteration 4, loss = 0.00674757\n",
      "Iteration 5, loss = 0.00354581\n",
      "Iteration 6, loss = 0.00208857\n",
      "Iteration 7, loss = 0.00144131\n",
      "Iteration 8, loss = 0.00115404\n",
      "Iteration 9, loss = 0.00101963\n",
      "Iteration 10, loss = 0.00094826\n",
      "Iteration 11, loss = 0.00090537\n",
      "Iteration 12, loss = 0.00088063\n",
      "Iteration 13, loss = 0.00086334\n",
      "Iteration 14, loss = 0.00084381\n",
      "Iteration 15, loss = 0.00082894\n",
      "Iteration 16, loss = 0.00082001\n",
      "Iteration 17, loss = 0.00081361\n",
      "Iteration 18, loss = 0.00080763\n",
      "Iteration 19, loss = 0.00080372\n",
      "Iteration 20, loss = 0.00080114\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(3,), learning_rate='constant',\n",
       "             learning_rate_init=0.01, max_fun=15000, max_iter=1000,\n",
       "             momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "             power_t=0.5, random_state=1234, shuffle=True, solver='adam',\n",
       "             tol=0.0001, validation_fraction=0.1, verbose=True,\n",
       "             warm_start=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = MLPRegressor(\n",
    "    hidden_layer_sizes = (3,),\n",
    "    activation = 'relu',\n",
    "    solver=\"adam\",\n",
    "    alpha=0.0001,\n",
    "    learning_rate_init=0.01,\n",
    "    max_iter=1000,\n",
    "    verbose = True,\n",
    "    random_state=1234\n",
    ")\n",
    "mod.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set mse: 0.0015977625173717084\n",
      "test set mse: 0.0015969791311892844\n"
     ]
    }
   ],
   "source": [
    "pred_train = mod.predict(X_train)\n",
    "pred_test = mod.predict(X_test)\n",
    "print('train set mse:', metrics.mean_squared_error(y_train,pred_train))\n",
    "print('test set mse:', metrics.mean_squared_error(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "hls = [(2,), (3,), (4,), (2, 2), (3, 3), (4, 4), (2,2,2), (3, 3, 3), (4, 4, 4)]\n",
    "\n",
    "param_grid = {\"hidden_layer_sizes\": hls, \"alpha\": [0.0001, 0.001, 0.01, 0.05]}\n",
    "\n",
    "mod_cv = GridSearchCV(\n",
    "    mod, \n",
    "    param_grid, \n",
    "    scoring= 'neg_root_mean_squared_error', \n",
    "    cv=5, n_jobs=4, refit=True, verbose=5\n",
    ")\n",
    "#mod_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done 180 out of 180 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.03052731\n",
      "Iteration 2, loss = 0.00065570\n",
      "Iteration 3, loss = 0.00065224\n",
      "Iteration 4, loss = 0.00065148\n",
      "Iteration 5, loss = 0.00064429\n",
      "Iteration 6, loss = 0.00063262\n",
      "Iteration 7, loss = 0.00060585\n",
      "Iteration 8, loss = 0.00055754\n",
      "Iteration 9, loss = 0.00054896\n",
      "Iteration 10, loss = 0.00054065\n",
      "Iteration 11, loss = 0.00054377\n",
      "Iteration 12, loss = 0.00054238\n",
      "Iteration 13, loss = 0.00053961\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=MLPRegressor(activation='relu', alpha=0.0001,\n",
       "                                    batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                                    early_stopping=False, epsilon=1e-08,\n",
       "                                    hidden_layer_sizes=(3,),\n",
       "                                    learning_rate='constant',\n",
       "                                    learning_rate_init=0.01, max_fun=15000,\n",
       "                                    max_iter=1000, momentum=0.9,\n",
       "                                    n_iter_no_change=10,\n",
       "                                    nesterovs_momentum=True, power_t=0.5,\n",
       "                                    random_state=12...ffle=True,\n",
       "                                    solver='adam', tol=0.0001,\n",
       "                                    validation_fraction=0.1, verbose=True,\n",
       "                                    warm_start=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.05],\n",
       "                         'hidden_layer_sizes': [(2,), (3,), (4,), (2, 2),\n",
       "                                                (3, 3), (4, 4), (2, 2, 2),\n",
       "                                                (3, 3, 3), (4, 4, 4)]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_root_mean_squared_error', verbose=5)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set mse: 0.001041105668518042\n",
      "test set mse: 0.0010526347046692164\n"
     ]
    }
   ],
   "source": [
    "pred_train = mod_cv.best_estimator_.predict(X_train)\n",
    "pred_test = mod_cv.best_estimator_.predict(X_test)\n",
    "print('train set mse:', metrics.mean_squared_error(y_train,pred_train))\n",
    "print('test set mse:', metrics.mean_squared_error(y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
